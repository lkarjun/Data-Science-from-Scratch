{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 32-bit ('data-science': pipenv)",
   "display_name": "Python 3.8.5 32-bit ('data-science': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "9ca7c1a4692349285564319c9a70eca76febac1ea81353f7bffc0810cb54cd0e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linearalgebra import dot, Vector\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x: Vector, beta: Vector) -> float:\n",
    "    '''assumes that the first element of x is 1'''\n",
    "    return dot(x, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(x: Vector, y: float, beta: Vector) -> float:\n",
    "    return predict(x, beta) -y\n",
    "\n",
    "def squared_error(x: Vector, y: float, beta: Vector) -> float:\n",
    "    return error(x, y, beta) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = [1, 2, 3]\n",
    "y = 30\n",
    "beta = [4, 4, 4] \n",
    "assert error(x, y, beta) == -6\n",
    "assert squared_error(x, y, beta) == 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqerror_gradient(x: Vector, y: float, beta: Vector) -> Vector:\n",
    "    err = error(x, y, beta)\n",
    "    return [2 * err * x_i for x_i in x]\n",
    "\n",
    "assert sqerror_gradient(x, y, beta) == [-12, -24, -36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tqdm\n",
    "from linearalgebra import vector_mean\n",
    "from GradientDescent import gradient_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_fit(xs: List[Vector], ys: List[float], learning_rate: float = 0.001, num_steps: int = 1000, batch_size: int = 1) -> Vector:\n",
    "    '''find the beta that minimizes the sum of squared errors assuming the model y = dot(x, beta).'''\n",
    "    # Start with a random guess\n",
    "    guess = [random.random() for _ in xs[0]]\n",
    "    for _ in tqdm.trange(num_steps, des='least squares fit'):\n",
    "        for start in range(0, len(xs), batch_size):\n",
    "            batch_xs = xs[start: start+batch_size]\n",
    "            batch_ys = ys[start: start+batch_size]\n",
    "\n",
    "            gradient = vector_mean([sqerror_gradient(x, y, guess) for\n",
    "                            x, y in zip(batch_xs, batch_ys)])\n",
    "            guess = gradient_step(guess, gradient, -learning_rate)\n",
    "            return guess"
   ]
  },
  {
   "source": [
    "# Goodness of Fit"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_sum_of_squares(y: Vector) -> float:\n",
    "    '''the total squared variation of y_i from their mean'''\n",
    "    return sum(v ** 2 for v in de_mean(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_r_squared(xs: List[Vector], ys: Vector, beta: Vector) -> float:\n",
    "    sum_of_squared_errors = sum(error(x, y, beta) ** 2 for x, y in zip(xs, ys))\n",
    "    return 1.0 - sum_of_squared_errors/total_sum_of_squares(ys)"
   ]
  },
  {
   "source": [
    "# Digression: The Bootstrap"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}